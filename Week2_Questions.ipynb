{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set: Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start your problem set by importing the following if you haven't already\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Boolean Search Result List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_list(arr1, arr2, barr):\n",
    "    \"\"\"(np.array, np.array, np.array) -> None \n",
    "    Given 3 np arrays, for each value in the first one, if the value is\n",
    "    also in the second one (but not necesarrily at the same spot) change\n",
    "    the value of barr at the index of the first array from 0 -> 1. \n",
    "    \n",
    "    Assume that barr is originally all zeros. arr1 and arr2 may have different lenths\n",
    "    but barr should have the same length as arr1.\n",
    "    \n",
    "    This function should not return anything. It should modify the array barr. \n",
    "    It should not modify arr1 or arr2.\n",
    "    \n",
    "    Examples:\n",
    "    >>> arr1 = np.array([5, 2, 3, 6])\n",
    "    >>> arr2 = np.array([6, 2, 9])\n",
    "    >>> barr = np.zeros(len(arr1))\n",
    "    >>> boolean_list(, , np.array([0, 0, 0, 0]))\n",
    "    >>> barr\n",
    "    np.array([0, 1, 0, 1])\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Linear Equations and Fitting Data\n",
    "\n",
    "### Part 1:\n",
    "In this question, we will manually calculate the parameters for a best fit line. Don't worry if you don't fully understand the math, just work through the coding parts of the questions. All the necessary mathematics/formula are given, you just have to convert them to code.\n",
    "\n",
    "In matrix notation, the equation for the best fit line of a function in terms of two paraemters, $m$ and $b$ when we have measured $n$ data points is:\n",
    "\n",
    "$$\n",
    "\\vec{y} = X \n",
    "\\begin{bmatrix}\n",
    "    b \\\\\n",
    "    m\n",
    "\\end{bmatrix} \\\\\n",
    "\\begin{bmatrix}\n",
    "    y_1 \\\\\n",
    "    y_2 \\\\\n",
    "    ... \\\\\n",
    "    y_n\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "    1 & x_1 \\\\\n",
    "    1 & x_2 \\\\\n",
    "    .. & .. \\\\\n",
    "    1 & x_n\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    b \\\\\n",
    "    m\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "To solve this matrix equation we must solve the expression:\n",
    "\n",
    "$$ \n",
    "\\begin{bmatrix}\n",
    "    b \\\\\n",
    "    m\n",
    "\\end{bmatrix}\n",
    " = (X^T X)^{-1} X^T \n",
    "\\vec{y}\n",
    "$$\n",
    "\n",
    "Write a function that takes in the matrix and the vector and returns a list [b, m]. You should use numpy functions to perform the operations on the matrix since operations such as inverse are fairly difficult to code by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_params(X, y):\n",
    "    \"\"\"\n",
    "    Solve the matrix equation listed above and return a list: [b, m]\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "# Once you have written the function, text it with this matrix and vector. \n",
    "# Store the value b and m as a variable for the next step.\n",
    "x = [3.2, 6.7, 2.3, 5.2, 4.7]\n",
    "y = np.array([8.4, 20.3, 7.1, 16.3, 13.8])\n",
    "\n",
    "X = np.array([[1, i] for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2:\n",
    "\n",
    "Now that you have the values $b$ and $m$, write the following in Python as a function of $b$, $m$ and $x$.\n",
    "\n",
    "$$ f(x) = mx + b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the function as a Python function like \n",
    "# we did when we did when we did root finding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to plot our \"data\" and the fit we just manually calculated. I have given you the scatter plot of the \"data\", now add to it a plot that plots some x values vs the fit function you just created at those values. \n",
    "\n",
    "Hint: Use np.linspace(...) to generate your x values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1042e39b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhEGXpEb8H243egKVDyV4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103fb2b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Starter code to make the plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, Y)\n",
    "\n",
    "# Add the code to plot the line here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Numerical Derivatives\n",
    "\n",
    "### Part 1:\n",
    "\n",
    "Define a function, F, of which you will later take the numerical derivative. You can make it any function you want but I suggest you start with something simple. My solution, posted later will be for $F(x) = x^2$ as we used in the root finding method so you can start with that and try changing it after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define your function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2:\n",
    "\n",
    "Now write a function that takes in your function above, the point we are evaluating at and the \"time step\" $h$ and calculate the **numerical** derivative.\n",
    "\n",
    "In mathematical terms, we want a numerical solution for:\n",
    "\n",
    "$$ \\left(\\frac{\\mathop{d}}{\\mathop{dx}} F(x)\\right)_{x = a} $$\n",
    "\n",
    "Hint: Recall the formalism of the derivative in terms of limits from first year calculus (ie MATA30 or equivalent). Solve this for small $h$ instead of the limit as it goes to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv(F, a, h):\n",
    "    \"\"\"\n",
    "    Calculate the numerical derivative of F(x) evaluated at a.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus (Part 3):\n",
    "\n",
    "If you want an extra challenge, use your numerical derivative method above to improve the bisection method by taking the interpolated derivative instead of the actual midpoint. This then becomes Newton's Method (which you have seen in calculus). Compare the error at different numbers of iterations to see that it does converge faster. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
